---
name: scraper-architecture
description: "Ô∏è Arquitectura de Scrapers: Separaci√≥n de Configuraci√≥n y L√≥gica"
type: documentation
created:
  2025-11-06T00:00:00.000Z
  
updated:
  2025-11-06T00:00:00.000Z
  
tags: ["documentation", "integration"]
category: integration
---

# üèóÔ∏è Arquitectura de Scrapers: Separaci√≥n de Configuraci√≥n y L√≥gica

An√°lisis de la separaci√≥n entre configuraci√≥n y l√≥gica en los scrapers de dendrita.

---

## ‚úÖ Separaci√≥n Verificada

### üìä Configuraci√≥n (Datos)

**Ubicaci√≥n:** Archivos locales JSON (paradigma de .dendrita)

#### Calendar Scraper
- **Archivo:** `.dendrita/users/[user-id]/scrapers-config.json`
- **Campos de configuraci√≥n:**
  - `user_id`, `profile_id`, `calendar_id`
  - `enabled`, `time_min_offset_days`, `time_max_offset_days`
  - `max_results`, `single_events`, `sync_attendees`, `sync_metadata`
  - `last_sync_at`, `last_sync_status`, `last_sync_error`
  - `metadata` (JSONB para campos adicionales)

#### Drive Scraper
- **Archivo (workspace-level):** `workspaces/[workspace]/scrapers-config.json`
- **Archivo (user-level):** `.dendrita/users/[user-id]/scrapers-config.json`
- **Campos de configuraci√≥n:**
  - `user_id`, `profile_id`, `workspace` (opcional, solo para workspace-level), `config_name`
  - `enabled`, `folder_ids[]`, `include_subfolders`
  - `max_results`, `page_token`
  - `extract_permissions`, `extract_revisions`, `extract_content`, `extract_metadata`, `extract_thumbnail`
  - `root_files_metadata_only` (si true, archivos sueltos en root solo se scrapean con metadata)
  - `mime_type_filter[]`, `date_min`, `date_max`
  - `last_sync_at`, `last_sync_status`, `last_sync_error`, `last_sync_file_count`
  - `metadata` (JSONB para campos adicionales)

#### Gmail Scraper
- **Archivo:** `workspaces/[workspace]/scrapers-config.json`
- **Campos de configuraci√≥n:**
  - `user_id`, `profile_id`, `config_name`
  - `enabled`, `search_query`
  - `max_results`, `page_token`
  - `date_min`, `date_max`
  - `extract_attachments`, `extract_labels`, `extract_threads`, `extract_full_body`, `extract_metadata`
  - `auto_label`
  - `last_sync_at`, `last_sync_status`, `last_sync_error`, `last_sync_message_count`
  - `metadata` (JSONB para campos adicionales)

**Paradigm:** Local JSON files (see `.dendrita/docs/TECHNICAL-PARADIGMS.md`)
**Ejemplos:** `workspaces/template/scrapers-config.json.example`, `.dendrita/users/scrapers-config.json.example`

---

### üîß L√≥gica (C√≥digo)

**Ubicaci√≥n:** Servicios TypeScript

#### Calendar Scraper
- **Servicio:** `.dendrita/integrations/services/google/calendar-scraper.ts`
- **Clase:** `CalendarScraper`
- **M√©todos principales:**
  - `loadConfigFromProfile()` - Carga configuraci√≥n desde Supabase
  - `upsertConfig()` - Crea/actualiza configuraci√≥n
  - `scrapeForUser()` - Ejecuta scraping seg√∫n configuraci√≥n
  - `processEvent()` - Procesa un evento individual
  - `processEventInstance()` - Procesa instancia de evento recurrente
  - `processAttendees()` - Procesa asistentes
  - `calculateEventHash()` - Calcula hash para detectar cambios

#### Drive Scraper
- **Servicio:** `.dendrita/integrations/services/google/drive-scraper.ts`
- **Clase:** `DriveScraper`
- **M√©todos principales:**
  - `loadConfigFromWorkspace()` - Carga configuraci√≥n desde workspace
  - `loadConfigFromUser()` - Carga configuraci√≥n desde usuario (user-level)
  - `saveConfig()` - Guarda configuraci√≥n en workspace
  - `saveUserConfig()` - Guarda configuraci√≥n en usuario (user-level)
  - `upsertConfig()` - Crea/actualiza configuraci√≥n (soporta ambos niveles)
  - `scrapeForUser()` - Ejecuta scraping seg√∫n configuraci√≥n (soporta ambos niveles)
  - `processFile()` - Procesa un archivo individual (respeta `root_files_metadata_only`)
  - `getFilePermissions()` - Obtiene permisos de archivo
  - `getFileRevisions()` - Obtiene revisiones de archivo
  - `getFileContent()` - Extrae contenido de archivo
  - `calculateFileHash()` - Calcula hash para detectar cambios
  - `buildFolderPath()` - Construye ruta de carpetas

#### Gmail Scraper
- **Servicio:** `.dendrita/integrations/services/google/gmail-scraper.ts`
- **Clase:** `GmailScraper`
- **M√©todos principales:**
  - `loadConfigFromProfile()` - Carga configuraci√≥n desde Supabase
  - `upsertConfig()` - Crea/actualiza configuraci√≥n
  - `scrapeForUser()` - Ejecuta scraping seg√∫n configuraci√≥n
  - `processMessage()` - Procesa un mensaje individual
  - `extractAttachments()` - Extrae adjuntos
  - `createOrUpdateLabel()` - Crea/actualiza etiquetas

---

## üîÑ Flujo de Separaci√≥n

### 1. Carga de Configuraci√≥n
```typescript
// Drive Scraper: Cargar desde workspace o usuario
let configs: DriveScrapingConfig[] = [];

if (workspace) {
  // Cargar configs del workspace
  configs = await driveScraper.loadConfigFromWorkspace(workspace, userId);
} else {
  // Cargar configs a nivel de usuario
  configs = await driveScraper.loadConfigFromUser(userId);
}

// Configuraci√≥n es solo datos, no l√≥gica
configs.forEach(config => {
  // L√≥gica usa configuraci√≥n para decidir qu√© hacer
  if (config.enabled) {
    await driveScraper.scrapeForUser(userId, profileId, workspace);
  }
});
```

### 2. Ejecuci√≥n de L√≥gica
```typescript
// L√≥gica lee configuraci√≥n y ejecuta seg√∫n par√°metros
async scrapeForUser(userId: string, profileId?: string): Promise<ScrapingResult[]> {
  // 1. Cargar configuraci√≥n (datos)
  const configs = await this.loadConfigFromProfile(userId, profileId);
  
  // 2. Ejecutar l√≥gica seg√∫n configuraci√≥n
  for (const config of configs) {
    if (!config.enabled) continue;
    
    // L√≥gica de scraping usa configuraci√≥n
    const events = await this.calendarService.listEvents({
      calendarId: config.calendar_id,
      timeMin: this.calculateTimeMin(config.time_min_offset_days),
      timeMax: this.calculateTimeMax(config.time_max_offset_days),
      maxResults: config.max_results,
      singleEvents: config.single_events,
    });
    
    // Procesar eventos seg√∫n configuraci√≥n
    for (const event of events) {
      await this.processEvent(config, event);
      if (config.sync_attendees) {
        await this.processAttendees(eventId, event.attendees);
      }
    }
  }
}
```

---

## ‚úÖ Ventajas de la Separaci√≥n

### 1. **Configuraci√≥n Din√°mica**
- ‚úÖ Puedes cambiar configuraci√≥n sin modificar c√≥digo
- ‚úÖ Configuraci√≥n se almacena en Supabase (persistente)
- ‚úÖ M√∫ltiples configuraciones por usuario/perfil/workspace

### 2. **L√≥gica Reutilizable**
- ‚úÖ Mismo c√≥digo funciona con diferentes configuraciones
- ‚úÖ L√≥gica centralizada en servicios TypeScript
- ‚úÖ F√°cil de mantener y testear

### 3. **Escalabilidad**
- ‚úÖ Puedes agregar nuevas configuraciones sin cambiar c√≥digo
- ‚úÖ Puedes modificar l√≥gica sin afectar configuraciones existentes
- ‚úÖ Configuraciones pueden ser creadas/actualizadas via API

### 4. **Separaci√≥n de Responsabilidades**
- ‚úÖ **Configuraci√≥n:** Define QU√â hacer (par√°metros, filtros, opciones)
- ‚úÖ **L√≥gica:** Define C√ìMO hacerlo (algoritmos, procesamiento, transformaci√≥n)

---

## üìã M√©todos de Configuraci√≥n

### Crear/Actualizar Configuraci√≥n
```typescript
// Calendar Scraper
await calendarScraper.upsertConfig({
  user_id: '[user-id]',
  profile_id: '[profile-id]',
  calendar_id: 'primary',
  enabled: true,
  time_min_offset_days: -30,
  time_max_offset_days: 365,
  max_results: 2500,
  single_events: true,
  sync_attendees: true,
  sync_metadata: true,
});

// Drive Scraper (workspace-level)
await driveScraper.upsertConfig({
  user_id: '[user-id]',
  profile_id: '[profile-id]',
  workspace: '[workspace-name]',
  config_name: '[config-name]',
  enabled: true,
  folder_ids: ['1ABC123...'],
  include_subfolders: true,
  max_results: 1000,
  extract_permissions: true,
  extract_metadata: true,
  root_files_metadata_only: false,
});

// Drive Scraper (user-level)
await driveScraper.upsertConfig({
  user_id: '[user-id]',
  config_name: 'my-drive-root',
  enabled: true,
  folder_ids: ['root'],
  include_subfolders: true,
  max_results: 10000,
  extract_permissions: true,
  extract_metadata: true,
  extract_content: false,
  root_files_metadata_only: true, // Solo metadata para archivos sueltos en root
});
```

### Cargar Configuraci√≥n
```typescript
// Carga configuraci√≥n desde Supabase
const configs = await scraper.loadConfigFromProfile(userId, profileId);

// Configuraci√≥n es solo datos estructurados
configs.forEach(config => {
  console.log(`Calendar: ${config.calendar_name}`);
  console.log(`Enabled: ${config.enabled}`);
  console.log(`Time range: ${config.time_min_offset_days} to ${config.time_max_offset_days} days`);
});
```

---

## üéØ Interfaces TypeScript

### Calendar ScrapingConfig
```typescript
interface ScrapingConfig {
  user_id: string;
  profile_id?: string;
  calendar_id: string;
  calendar_name?: string;
  enabled?: boolean;
  time_min_offset_days?: number;
  time_max_offset_days?: number;
  max_results?: number;
  single_events?: boolean;
  sync_attendees?: boolean;
  sync_metadata?: boolean;
}
```

### Drive ScrapingConfig
```typescript
interface DriveScrapingConfig {
  user_id: string;
  profile_id?: string;
  workspace?: string; // Opcional: solo para workspace-level configs
  config_name: string;
  enabled?: boolean;
  folder_ids: string[]; // Puede incluir "root" para scrapear desde root
  include_subfolders?: boolean;
  max_results?: number;
  page_token?: string;
  extract_permissions?: boolean;
  extract_revisions?: boolean;
  extract_content?: boolean;
  extract_metadata?: boolean;
  extract_thumbnail?: boolean;
  root_files_metadata_only?: boolean; // Si true, archivos sueltos en root solo metadata
  mime_type_filter?: string[];
  date_min?: string;
  date_max?: string;
}
```

---

## ‚úÖ Conclusi√≥n

**La separaci√≥n entre configuraci√≥n y l√≥gica est√° bien implementada:**

1. ‚úÖ **Configuraci√≥n en archivos locales JSON** (paradigma de .dendrita)
2. ‚úÖ **L√≥gica en servicios TypeScript** (c√≥digo reutilizable)
3. ‚úÖ **M√©todos de carga separados** (`loadConfigFromWorkspace()`, `loadConfigFromUser()`)
4. ‚úÖ **M√©todos de ejecuci√≥n separados** (`scrapeForUser()`, `processEvent()`, `processFile()`)
5. ‚úÖ **Interfaces TypeScript claras** para tipado
6. ‚úÖ **Schemas SQL documentados** para estructura de datos
7. ‚úÖ **Soporte para configs a nivel de usuario y workspace** (Drive Scraper)

**Beneficios:**
- Configuraci√≥n din√°mica sin cambiar c√≥digo
- L√≥gica reutilizable con diferentes configuraciones
- F√°cil mantenimiento y escalabilidad
- Separaci√≥n clara de responsabilidades

---

**√öltima actualizaci√≥n:** 2025-01-28
**Versi√≥n:** 2.0
**Cambios:**
- ‚úÖ Agregado soporte para Drive Scraper a nivel de usuario
- ‚úÖ Agregado campo `root_files_metadata_only` para optimizar scraping desde root
- ‚úÖ Actualizados m√©todos para soportar ambos niveles (usuario y workspace)

